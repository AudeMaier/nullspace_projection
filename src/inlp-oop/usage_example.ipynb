{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "import inlp_dataset_handler\n",
    "import inlp\n",
    "import inlp_linear_model\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression, Ridge, SGDClassifier\n",
    "from sklearn.svm import LinearSVC, SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_dev = np.random.rand(1000,100) - 0.5, np.random.rand(1000,100) - 0.5\n",
    "y_train, y_dev = np.sum(x_train, axis = 1) > 0, np.sum(x_dev, axis = 1) > 0\n",
    "\n",
    "inlp_dataset = inlp_dataset_handler.ClassificationDatasetHandler(x_train, y_train, x_dev, y_dev, dropout_rate = 0, Y_train_main = None, Y_dev_main = None, by_class = False, equal_chance_for_main_task_labels = False)\n",
    "\n",
    "inlp_model_handler = inlp_linear_model.SKlearnClassifier(LinearSVC, {\"dual\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 4, accuracy: 0.506: 100%|██████████| 5/5 [00:00<00:00, 23.40it/s]\n"
     ]
    }
   ],
   "source": [
    "P, rowspace_projections, Ws = inlp.run_INLP(num_classifiers = 5, input_dim = 100, is_autoregressive = True, min_accuracy = 0, dataset_handler = inlp_dataset, model = inlp_model_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_sanity_check(P, Ws, x_train):\n",
    "\n",
    "    assert np.allclose(P.dot(P), P)\n",
    "    assert np.allclose(Ws[0].dot(P.dot(x_train[0])), 0.0)\n",
    "\n",
    "    for w in Ws:\n",
    "        for w2 in Ws:\n",
    "            if w is w2: continue\n",
    "            assert np.allclose(w.dot(w2.T).item(), 0.0)\n",
    "            \n",
    "do_sanity_check(P, Ws, x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Siamese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1, x_train2 = np.random.rand(1000,100) - 0.5,  np.random.rand(1000,100) - 0.5,\n",
    "x_dev1, x_dev2 =  np.random.rand(1000,100) - 0.5, np.random.rand(1000,100) - 0.5\n",
    "\n",
    "y_train = (np.sign(np.sum(x_train1, axis = 1)) ==  np.sign(np.sum(x_train2, axis = 1))).astype(int)\n",
    "y_dev = (np.sign(np.sum(x_dev1, axis = 1)) ==  np.sign(np.sum(x_dev2, axis = 1))).astype(int)\n",
    "\n",
    "inlp_dataset = inlp_dataset_handler.SiameseDatasetHandler((x_train1, x_train2), y_train, (x_dev1, x_dev2), y_dev, dropout_rate = 0, Y_train_main = None, Y_dev_main = None, by_class = False, equal_chance_for_main_task_labels = False)\n",
    "params = {\"num_iter\": 25, \"input_dim\": 100, \"hidden_dim\": 32, \"batch_size\": 64, \"verbose\": False, \"device\": \"cuda\",\n",
    "         \"compare_by\": \"cosine\", \"same_weights\": True}\n",
    "inlp_model_handler = inlp_linear_model.SiameseLinearClassifier(model_params = params, concat_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[AINFO:root:         Name               Type Params\n",
      "0          l1             Linear    3 K\n",
      "1  cosine_sim   CosineSimilarity    0  \n",
      "2     loss_fn  BCEWithLogitsLoss    0  \n",
      "\n",
      "iteration: 0, accuracy: 0.866992175579071:   0%|          | 0/3 [00:05<?, ?it/s]\u001b[A\n",
      "iteration: 0, accuracy: 0.866992175579071:  33%|███▎      | 1/3 [00:05<00:10,  5.45s/it]\u001b[AINFO:root:         Name               Type Params\n",
      "0          l1             Linear    3 K\n",
      "1  cosine_sim   CosineSimilarity    0  \n",
      "2     loss_fn  BCEWithLogitsLoss    0  \n",
      "\n",
      "iteration: 1, accuracy: 0.4925781190395355:  33%|███▎      | 1/3 [00:11<00:10,  5.45s/it]\u001b[A\n",
      "iteration: 1, accuracy: 0.4925781190395355:  67%|██████▋   | 2/3 [00:11<00:05,  5.51s/it]\u001b[AINFO:root:         Name               Type Params\n",
      "0          l1             Linear    3 K\n",
      "1  cosine_sim   CosineSimilarity    0  \n",
      "2     loss_fn  BCEWithLogitsLoss    0  \n",
      "\n",
      "iteration: 2, accuracy: 0.501171886920929:  67%|██████▋   | 2/3 [00:16<00:05,  5.51s/it] \u001b[A\n",
      "iteration: 2, accuracy: 0.501171886920929: 100%|██████████| 3/3 [00:16<00:00,  5.63s/it]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "#inlp_model_handler.train_model(inlp_dataset)\n",
    "P, rowspace_projections, Ws = inlp.run_INLP(num_classifiers = 3, input_dim = 100, is_autoregressive = True, min_accuracy = 0, dataset_handler = inlp_dataset, model = inlp_model_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## note that the cosine/l2 distance loss is no longer convex, so w_i.dot(w_j) != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02186606,  0.0346785 , -0.02964997, ...,  0.02251494,\n",
       "         0.06070557,  0.03205736],\n",
       "       [-0.00448008, -0.02645985,  0.03417505, ..., -0.00667388,\n",
       "        -0.01322363, -0.00543375],\n",
       "       [-0.00049647,  0.01373247, -0.02147561, ...,  0.00711308,\n",
       "         0.08852425,  0.019908  ],\n",
       "       ...,\n",
       "       [ 0.01660385,  0.02621097, -0.01645809, ..., -0.02676257,\n",
       "        -0.05707281, -0.02487635],\n",
       "       [-0.00046501,  0.00114721,  0.09579111, ..., -0.02665293,\n",
       "        -0.15518732, -0.00907945],\n",
       "       [-0.00971164,  0.05872897, -0.03290517, ...,  0.00484753,\n",
       "         0.0505405 ,  0.00218303]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ws[0].dot(Ws[1].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.69745433042437e-06\n",
      "0.000550595020200669\n"
     ]
    }
   ],
   "source": [
    "print(np.linalg.norm(P.dot(P) - P))\n",
    "print( np.linalg.norm( Ws[-1][:32, :].dot(P.dot(x_train1[0]))) ) # note that the norm is not exactly 0 due to pytorch floating point precision"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
